{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuClass": "premium"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#â—‡Reference"
      ],
      "metadata": {
        "id": "qr4iQ0o7eVwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face Whisper:</br>\n",
        "https://huggingface.co/docs/transformers/model_doc/whisper"
      ],
      "metadata": {
        "id": "2SA4SDBzegCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install Tranformers and datasets"
      ],
      "metadata": {
        "id": "c5g9NTF_Ixad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClniiYCWHK4b"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.14\n",
        "#!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up and prepair sample data"
      ],
      "metadata": {
        "id": "S2G0ZQLZpzfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import WhisperProcessor, TFWhisperForConditionalGeneration\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import google.colab as colab\n",
        "import numpy as np\n",
        "\n",
        "model_name = 'whisper-tiny.en'\n",
        "model_path = \"openai/%s\" %(model_name)\n",
        "saved_model_dir = '/content/tf_whisper_saved'\n",
        "\n",
        "work_dir = '/content/work'\n",
        "os.makedirs(work_dir, exist_ok=True)\n",
        "tflite_model_path = os.path.join(work_dir, \"%s.tflite\" %(model_name))\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(model_path)\n",
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "input_features = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"tf\").input_features\n",
        "input_features"
      ],
      "metadata": {
        "id": "NJUJMPUKAhb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dat = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"tf\").input_features"
      ],
      "metadata": {
        "id": "2HxyqETZSEwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[0][\"audio\"][\"array\"]"
      ],
      "metadata": {
        "id": "G5MZZ7kcS7UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define generation-enabled TF model"
      ],
      "metadata": {
        "id": "s8Q75mOBCZOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenerateModel(tf.Module):\n",
        "  def __init__(self, model, max_new_tokens=223):\n",
        "    super(GenerateModel, self).__init__()\n",
        "    self.model = TFWhisperForConditionalGeneration.from_pretrained(model)\n",
        "    self.max_new_tokens = max_new_tokens\n",
        "\n",
        "  @tf.function(\n",
        "    # shouldn't need static batch size, but throws exception without it (needs to be fixed)\n",
        "    input_signature=[\n",
        "      tf.TensorSpec((1, 80, 3000), tf.float32, name=\"input_features\"),\n",
        "    ],\n",
        "  )\n",
        "  def generate(self, input_features):\n",
        "    outputs = self.model.generate(\n",
        "      input_features,\n",
        "      max_new_tokens=self.max_new_tokens, #change as needed\n",
        "      return_dict_in_generate=True,\n",
        "    )\n",
        "    return {\"sequences\": outputs[\"sequences\"]}"
      ],
      "metadata": {
        "id": "TsTRnn-wBqOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load pre trained TF Whisper Tiny model and evaluate it"
      ],
      "metadata": {
        "id": "pljpioLsJOtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerateModel(model_path)"
      ],
      "metadata": {
        "id": "fgZcxduCT7-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_ids = model.generate(input_features)[\"sequences\"]\n",
        "print(generated_ids)\n",
        "\n",
        "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "transcription"
      ],
      "metadata": {
        "id": "-RuFFohHg2ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, saved_model_dir, signatures={\"serving_default\": model.generate})"
      ],
      "metadata": {
        "id": "xmRcf6QFR5y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert saved model to TFLite model"
      ],
      "metadata": {
        "id": "TY_79jFEJYyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the tflite model (flatbuffers)\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "wSMrJo7hJ95c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate TFLite model"
      ],
      "metadata": {
        "id": "vk32fMh1qmn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(tflite_model_path)\n",
        "\n",
        "tflite_generate = interpreter.get_signature_runner()\n",
        "generated_ids = tflite_generate(input_features=input_features)['sequences']\n",
        "print(generated_ids)\n",
        "\n",
        "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "transcription"
      ],
      "metadata": {
        "id": "dLkMa_36PgW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save Vocablaries: Decoder"
      ],
      "metadata": {
        "id": "nJ2SQhfoq_tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_vocab(save_directory: str, processor: WhisperProcessor) -> str:\n",
        "  # save vocablary\n",
        "  vocab_file = os.path.join(save_directory, \"vocab.json\")\n",
        "  with open(vocab_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(processor.tokenizer.encoder, f, indent=2, sort_keys=True, ensure_ascii=False)\n",
        "\n",
        "  # save added_vocablary\n",
        "  added_vocab_file = os.path.join(save_directory, \"added_vocab.json\")\n",
        "  with open(added_vocab_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(processor.tokenizer.added_tokens_encoder, f, indent=2, sort_keys=True, ensure_ascii=False)\n",
        "\n",
        "  # save all_special_ids\n",
        "  all_special_ids_file = os.path.join(save_directory, \"special_ids.json\")\n",
        "  with open(all_special_ids_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(processor.tokenizer.all_special_ids, f, indent=2, sort_keys=True, ensure_ascii=False)\n",
        "\n",
        "  return vocab_file, added_vocab_file, all_special_ids_file"
      ],
      "metadata": {
        "id": "1EzpUhrPIFQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_vocab(work_dir, processor)"
      ],
      "metadata": {
        "id": "zz8oULhYhxzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download TFLite model"
      ],
      "metadata": {
        "id": "JPY-rJ2PsiEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(model_name, format=\"zip\", root_dir=work_dir)\n",
        "colab.files.download(model_name + \".zip\")"
      ],
      "metadata": {
        "id": "K_mNuDioUbrg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}