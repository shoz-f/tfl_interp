# Style-based GAN

```elixir
File.cd!(__DIR__)
# for windows JP
System.shell("chcp 65001")
System.put_env("NNCOMPILED", "YES")

Mix.install([
  {:tfl_interp, "~> 0.1.13"},
  {:cimg, "~> 0.1.19"},
  {:kino, "~> 0.7.0"}
])
```

## 0.Original work

"Training Generative Adversarial Networks with Limited Data"

* https://arxiv.org/abs/2006.06676

GitHub: StyleGAN2 with adaptive discriminator augmentation

* https://github.com/NVlabs/stylegan2-ada

GitHub: sugyan/gan-playground

* https://github.com/sugyan/gan-playground

The tflite model `afhqdog.tflite` is converted from pretraind model in pickle format.

***Thanks a lot!!!***

---

## Implementation with TflInterp in Elixir

## 1.Defining the inference module: StyleGAN2ADA

* Model

  afhqdog.tflite: get from "https://github.com/shoz-f/tfl_interp/releases/download/0.0.1/afhqdog.tflite" if not existed.

* Pre-processing

  Make a latent - 512 size normal random number vector.

* Post-processing

  Convert float32 {-1.0, 1.0} to pixel and transpose NCHW to NHWC.

```elixir
defmodule StyleGAN2ADA do
  def apply(), do: gen_latants() |> apply()

  def apply(latants) do
    latants
    |> StyleGAN2ADA.Mapping.apply()
    |> StyleGAN2ADA.Synthesis.apply()
  end

  def gen_latants() do
    for _ <- 1..512, into: "", do: <<:rand.normal()::little-float-32>>
  end
end

defmodule StyleGAN2ADA.Mapping do
  alias TflInterp, as: NNInterp
  use NNInterp,
    model: "./model/afhqdog.mapping.tflite",
    url: "https://github.com/shoz-f/tfl_interp/releases/download/0.0.1/afhqdog.mapping.tflite",
    inputs: [f32: {1,512}],
    outputs: [f32: {1,16.512}]

  def apply(latants) do
    # preprocess
    input0 = latants

    # prediction
    output0 = session()
      |> NNInterp.set_input_tensor(0, input0)
      |> NNInterp.invoke()
      |> NNInterp.get_output_tensor(0)
    
    # postprocess
    output0
  end
end

defmodule StyleGAN2ADA.Synthesis do
  @width  512
  @height 512

  alias TflInterp, as: NNInterp
  use NNInterp,
    model: "./model/afhqdog.synthesis.tflite",
    url: "https://github.com/shoz-f/tfl_interp/releases/download/0.0.1/afhqdog.synthesis.tflite",
    inputs: [f32: {1,16,512}],
    outputs: [f32: {1,3,@height,@width}]

  def apply(dlatants) do
    # preprocess
    input0 = dlatants

    # prediction
    output0 = session()
      |> NNInterp.set_input_tensor(0, input0)
      |> NNInterp.invoke()
      |> NNInterp.get_output_tensor(0)

    # postprocess
    CImg.from_binary(output0, @width, @height, 1, 3, [{:range, {-1.0, 1.0}}, :nchw])
  end
end
```

Launch `StyleGAN2ADA.Mapping` and `StyleGAN2ADA.Synthesis`.

```elixir
# TflInterp.stop(StyleGAN2ADA)
StyleGAN2ADA.Mapping.start_link([])
StyleGAN2ADA.Synthesis.start_link([])
```

Display the properties of the `StyleGAN2ADA` model.

```elixir
TflInterp.info(StyleGAN2ADA)
```

## 2.Let's try it

Generate 8 photos by StyleGAN2ADA and display them.

```elixir
Enum.map(1..8, fn _ -> StyleGAN2ADA.apply() |> CImg.display_kino(:jpeg) end)
|> Kino.Layout.grid(columns: 4)
```

&#9633;
